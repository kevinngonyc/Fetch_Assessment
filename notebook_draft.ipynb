{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f529e05-5dfc-4e14-b55f-2d379dc8431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0d76f3-6d0c-4331-8801-4466c9dfabb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312610eb-a68b-4d02-8c17-3a715e9e8916",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a9a01d6a-cebf-4970-a208-737ddb49a212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee095edc-f2b0-48cc-8276-7d881ae0651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Her brother is a king.\",\n",
    "    \"His sister is a queen.\",\n",
    "    \"They can't dance.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ceb5d80-6203-4a38-9f96-a278064f9f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3426487e-01,  6.8651125e-02, -7.1860326e-05, ...,\n",
       "         5.4440424e-02, -8.0796704e-04,  4.2172940e-03],\n",
       "       [ 1.3438945e-01,  6.8506449e-02, -2.4290488e-04, ...,\n",
       "         5.4613810e-02, -6.0740544e-04,  3.9655287e-03],\n",
       "       [ 1.3048099e-01,  7.0870683e-02, -3.6374270e-03, ...,\n",
       "         5.7554800e-02,  8.8193323e-03,  2.7406658e-03]],\n",
       "      shape=(3, 384), dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.encode(sentences)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3b30b4-9fc8-4ff2-b834-1d6b722e5dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.8068, 0.1882],\n",
       "        [0.8068, 1.0000, 0.1774],\n",
       "        [0.1882, 0.1774, 1.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(embeddings, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754da3ea-0304-4094-8a55-6d09eccf2dc9",
   "metadata": {},
   "source": [
    "## Alternative (Unfinished) Implementation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d787040d-5cc4-40fa-a985-3cee0eec65cf",
   "metadata": {},
   "source": [
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf9a0102-1d8a-4f70-af61-d38b15ce3ecb",
   "metadata": {},
   "source": [
    "tokens = tokenizer.encode('Hello World!')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "raw",
   "id": "974b7967-a433-4d51-8b0d-23588cdff56b",
   "metadata": {},
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SentenceTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentenceTransformer, self).__init__()\n",
    "        self.bert = BERT()\n",
    "        self.pool = nn.AvgPool1d(kernel_size=768)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bert(x)\n",
    "        out = self.pool(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c353f2cc-2c7e-4941-8c3e-d865287ae6b5",
   "metadata": {},
   "source": [
    "model = SentenceTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8539c239-577f-4aaf-8b48-110d19c8dfb3",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a3827247-e847-4e48-b823-7f271b2ad367",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.linear = nn.Linear(384, n)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "class SentenceTransformerWithHeads(nn.Module):\n",
    "    def __init__(self, num_classes_a, num_classes_b):\n",
    "        super(SentenceTransformerWithHeads, self).__init__()\n",
    "        self.st = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        self.num_classes_a = num_classes_a\n",
    "        self.num_classes_b = num_classes_b\n",
    "        self.head_a = ClassificationHead(n=num_classes_a)\n",
    "        self.head_b = ClassificationHead(n=num_classes_b)\n",
    "\n",
    "    def forward(self, x, head):\n",
    "        features = torch.tensor(self.st.encode(x)).to(device)\n",
    "        if head == 'A':\n",
    "            out = self.head_a(features)\n",
    "        elif head == 'B':\n",
    "            out = self.head_b(features)\n",
    "        else:\n",
    "            raise ValueError(\"Please specify 'A' or 'B' for head\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9251f7a-bbe5-47f6-ac89-0ebdcde0f0ad",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "deb6d836-b90a-43ed-bae6-28773e161a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "11eeca7a-0bc9-4b01-88ea-e27c9a0c68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_a = load_dataset(\"fancyzhx/ag_news\", split=\"train\").with_format(\"torch\")\n",
    "test_dataset_a = load_dataset(\"fancyzhx/ag_news\", split=\"test\").with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3932fb9e-0564-4ebf-bbae-20d64d70d4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_a = 2000\n",
    "train_dataloader_a = DataLoader(train_dataset_a, batch_size=batch_size_a)\n",
    "test_dataloader_a = DataLoader(test_dataset_a, batch_size=batch_size_a)\n",
    "len(train_dataloader_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "aed5c044-b787-420e-b714-3545718462db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_b = load_dataset(\"zeroshot/twitter-financial-news-sentiment\", split=\"train\").with_format(\"torch\")\n",
    "test_dataset_b = load_dataset(\"zeroshot/twitter-financial-news-sentiment\", split=\"validation\").with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8390460c-d8e6-45fa-ba35-0e5fcdeafbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_b = 160\n",
    "train_dataloader_b = DataLoader(train_dataset_b, batch_size=batch_size_b)\n",
    "test_dataloader_b = DataLoader(test_dataset_b, batch_size=batch_size_b)\n",
    "len(train_dataloader_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "92f5d9ea-87a3-421c-9dfb-9cd47337749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader_a, dataloader_b, model, loss_fn, optimizer):\n",
    "    num_batches = len(dataloader_a)\n",
    "    model.train()\n",
    "    for i, (batch_a, batch_b) in enumerate(zip(dataloader_a, dataloader_b)):\n",
    "        X_a = batch_a['text']\n",
    "        y_a = batch_a['label'].to(device)\n",
    "        X_b = batch_b['text']\n",
    "        y_b = batch_b['label'].to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred_a = model(X_a, 'A')\n",
    "        loss_a = loss_fn(pred_a, y_a)\n",
    "        pred_b = model(X_b, 'B')\n",
    "        loss_b = loss_fn(pred_b, y_b)\n",
    "        loss = loss_a + loss_b\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 5 == 4:\n",
    "            loss = loss.item()\n",
    "            print(f\"loss: {loss:>7f}  [{i+1:>5d}/{num_batches:>5d}]\")\n",
    "\n",
    "def test(dataloader_a, dataloader_b, model, loss_fn):\n",
    "    num_batches = len(dataloader_a)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    \n",
    "    accuracy = MulticlassAccuracy()\n",
    "    f1_a = MulticlassF1Score(num_classes=model.num_classes_a, average=None)\n",
    "    precision_a = MulticlassPrecision(num_classes=model.num_classes_a, average=None)\n",
    "    recall_a = MulticlassRecall(num_classes=model.num_classes_a, average=None)\n",
    "\n",
    "    f1_b = MulticlassF1Score(num_classes=model.num_classes_b, average=None)\n",
    "    precision_b = MulticlassPrecision(num_classes=model.num_classes_b, average=None)\n",
    "    recall_b = MulticlassRecall(num_classes=model.num_classes_b, average=None)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_a, batch_b in zip(dataloader_a, dataloader_b):\n",
    "            X_a = batch_a['text']\n",
    "            y_a = batch_a['label'].to(device)\n",
    "            pred_a = model(X_a, 'A')\n",
    "\n",
    "            test_loss += loss_fn(pred_a, y_a).item()\n",
    "            accuracy.update(pred_a, y_a)\n",
    "            f1_a.update(pred_a, y_a)\n",
    "            precision_a.update(pred_a, y_a)\n",
    "            recall_a.update(pred_a, y_a)\n",
    "\n",
    "            X_b = batch_b['text']\n",
    "            y_b = batch_b['label'].to(device)\n",
    "            pred_b = model(X_b, 'B')\n",
    "\n",
    "            test_loss += loss_fn(pred_b, y_b).item()\n",
    "            accuracy.update(pred_b, y_b)\n",
    "            f1_b.update(pred_b, y_b)\n",
    "            precision_b.update(pred_b, y_b)\n",
    "            recall_b.update(pred_b, y_b)\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    loss_str = f\"Avg loss: {test_loss:>8f}\"\n",
    "    accuracy_str = f\"Accuracy: {(100*accuracy.compute()):>0.1f}%\"\n",
    "\n",
    "    precision_str_a = f\"Precision (A): {precision_a.compute()}\"\n",
    "    recall_str_a = f\"Recall (A): {recall_a.compute()}\"\n",
    "    f1_str_a = f\"F1-Score (A): {f1_a.compute()}\"\n",
    "\n",
    "    precision_str_b = f\"Precision (B): {precision_b.compute()}\"\n",
    "    recall_str_b = f\"Recall (B): {recall_b.compute()}\"\n",
    "    f1_str_b = f\"F1-Score (B): {f1_b.compute()}\"\n",
    "\n",
    "    print(f\"\"\"Test Error:\n",
    "    {loss_str}\n",
    "    {accuracy_str}\n",
    "    \n",
    "    {precision_str_a}\n",
    "    {recall_str_a}\n",
    "    {f1_str_a}\n",
    "    \n",
    "    {precision_str_b}\n",
    "    {recall_str_b}\n",
    "    {f1_str_b}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c496e1f2-734a-4588-9689-fcda23b3a5cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.488513  [    5/   60]\n",
      "loss: 2.463017  [   10/   60]\n",
      "loss: 2.446870  [   15/   60]\n",
      "loss: 2.419731  [   20/   60]\n",
      "loss: 2.386283  [   25/   60]\n",
      "loss: 2.335083  [   30/   60]\n",
      "loss: 2.325567  [   35/   60]\n",
      "loss: 2.417871  [   40/   60]\n",
      "loss: 2.217272  [   45/   60]\n",
      "loss: 2.449257  [   50/   60]\n",
      "loss: 2.140202  [   55/   60]\n",
      "loss: 2.204949  [   60/   60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tensor([[0],\n",
      "        [1]]) classes have zero instances in both the predictions and the ground truth labels. Precision is still logged as zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "    Avg loss: 2.179438\n",
      "    Accuracy: 82.6%\n",
      "\n",
      "    Precision (A): tensor([0.8182, 0.9154, 0.7548, 0.8764])\n",
      "    Recall (A): tensor([0.8621, 0.9400, 0.8637, 0.6795])\n",
      "    F1-Score (A): tensor([0.8396, 0.9276, 0.8056, 0.7655])\n",
      "\n",
      "    Precision (B): tensor([0.0000, 0.0000, 0.7063])\n",
      "    Recall (B): tensor([0., 0., 1.])\n",
      "    F1-Score (B): tensor([0.0000, 0.0000, 0.8278])\n",
      "    \n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165391  [    5/   60]\n",
      "loss: 2.073323  [   10/   60]\n",
      "loss: 2.057193  [   15/   60]\n",
      "loss: 2.170320  [   20/   60]\n",
      "loss: 2.102693  [   25/   60]\n",
      "loss: 2.010205  [   30/   60]\n",
      "loss: 2.080139  [   35/   60]\n",
      "loss: 2.327700  [   40/   60]\n",
      "loss: 1.900751  [   45/   60]\n",
      "loss: 2.367872  [   50/   60]\n",
      "loss: 1.828688  [   55/   60]\n",
      "loss: 1.963374  [   60/   60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tensor([[0],\n",
      "        [1]]) classes have zero instances in both the predictions and the ground truth labels. Precision is still logged as zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "    Avg loss: 1.942279\n",
      "    Accuracy: 84.2%\n",
      "\n",
      "    Precision (A): tensor([0.8604, 0.9137, 0.7802, 0.8650])\n",
      "    Recall (A): tensor([0.8532, 0.9584, 0.8595, 0.7421])\n",
      "    F1-Score (A): tensor([0.8568, 0.9355, 0.8179, 0.7989])\n",
      "\n",
      "    Precision (B): tensor([0.0000, 0.0000, 0.7063])\n",
      "    Recall (B): tensor([0., 0., 1.])\n",
      "    F1-Score (B): tensor([0.0000, 0.0000, 0.8278])\n",
      "    \n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.941443  [    5/   60]\n",
      "loss: 1.790649  [   10/   60]\n",
      "loss: 1.777463  [   15/   60]\n",
      "loss: 1.987257  [   20/   60]\n",
      "loss: 1.893212  [   25/   60]\n",
      "loss: 1.769475  [   30/   60]\n",
      "loss: 1.895535  [   35/   60]\n",
      "loss: 2.253718  [   40/   60]\n",
      "loss: 1.669129  [   45/   60]\n",
      "loss: 2.305464  [   50/   60]\n",
      "loss: 1.606261  [   55/   60]\n",
      "loss: 1.785047  [   60/   60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tensor([[0],\n",
      "        [1]]) classes have zero instances in both the predictions and the ground truth labels. Precision is still logged as zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "    Avg loss: 1.767275\n",
      "    Accuracy: 84.8%\n",
      "\n",
      "    Precision (A): tensor([0.8728, 0.9150, 0.7964, 0.8567])\n",
      "    Recall (A): tensor([0.8526, 0.9626, 0.8500, 0.7742])\n",
      "    F1-Score (A): tensor([0.8626, 0.9382, 0.8223, 0.8134])\n",
      "\n",
      "    Precision (B): tensor([0.0000, 0.0000, 0.7063])\n",
      "    Recall (B): tensor([0., 0., 1.])\n",
      "    F1-Score (B): tensor([0.0000, 0.0000, 0.8278])\n",
      "    \n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.778687  [    5/   60]\n",
      "loss: 1.582820  [   10/   60]\n",
      "loss: 1.573105  [   15/   60]\n",
      "loss: 1.850649  [   20/   60]\n",
      "loss: 1.735827  [   25/   60]\n",
      "loss: 1.589973  [   30/   60]\n",
      "loss: 1.754540  [   35/   60]\n",
      "loss: 2.188859  [   40/   60]\n",
      "loss: 1.498557  [   45/   60]\n",
      "loss: 2.251021  [   50/   60]\n",
      "loss: 1.445619  [   55/   60]\n",
      "loss: 1.650118  [   60/   60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tensor([[0],\n",
      "        [1]]) classes have zero instances in both the predictions and the ground truth labels. Precision is still logged as zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "    Avg loss: 1.635560\n",
      "    Accuracy: 85.1%\n",
      "\n",
      "    Precision (A): tensor([0.8795, 0.9173, 0.8022, 0.8522])\n",
      "    Recall (A): tensor([0.8532, 0.9637, 0.8453, 0.7889])\n",
      "    F1-Score (A): tensor([0.8662, 0.9399, 0.8232, 0.8193])\n",
      "\n",
      "    Precision (B): tensor([0.0000, 0.0000, 0.7063])\n",
      "    Recall (B): tensor([0., 0., 1.])\n",
      "    F1-Score (B): tensor([0.0000, 0.0000, 0.8278])\n",
      "    \n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.657891  [    5/   60]\n",
      "loss: 1.428973  [   10/   60]\n",
      "loss: 1.421852  [   15/   60]\n",
      "loss: 1.745885  [   20/   60]\n",
      "loss: 1.615106  [   25/   60]\n",
      "loss: 1.454816  [   30/   60]\n",
      "loss: 1.644817  [   35/   60]\n",
      "loss: 2.130281  [   40/   60]\n",
      "loss: 1.371516  [   45/   60]\n",
      "loss: 2.200944  [   50/   60]\n",
      "loss: 1.327703  [   55/   60]\n",
      "loss: 1.545658  [   60/   60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tensor([[0]]) classes have zero instances in both the predictions and the ground truth labels. Precision is still logged as zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "    Avg loss: 1.534158\n",
      "    Accuracy: 85.2%\n",
      "\n",
      "    Precision (A): tensor([0.8809, 0.9202, 0.8058, 0.8490])\n",
      "    Recall (A): tensor([0.8526, 0.9647, 0.8432, 0.7958])\n",
      "    F1-Score (A): tensor([0.8665, 0.9419, 0.8241, 0.8215])\n",
      "\n",
      "    Precision (B): tensor([0.0000, 1.0000, 0.7074])\n",
      "    Recall (B): tensor([0.0000, 0.0090, 1.0000])\n",
      "    F1-Score (B): tensor([0.0000, 0.0179, 0.8286])\n",
      "    \n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.566101  [    5/   60]\n",
      "loss: 1.313316  [   10/   60]\n",
      "loss: 1.307840  [   15/   60]\n",
      "loss: 1.663432  [   20/   60]\n",
      "loss: 1.520502  [   25/   60]\n",
      "loss: 1.351629  [   30/   60]\n",
      "loss: 1.557693  [   35/   60]\n",
      "loss: 2.076861  [   40/   60]\n",
      "loss: 1.275581  [   45/   60]\n",
      "loss: 2.154396  [   50/   60]\n",
      "loss: 1.239580  [   55/   60]\n",
      "loss: 1.463140  [   60/   60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tensor([[0]]) classes have zero instances in both the predictions and the ground truth labels. Precision is still logged as zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "    Avg loss: 1.454336\n",
      "    Accuracy: 85.5%\n",
      "\n",
      "    Precision (A): tensor([0.8857, 0.9240, 0.8108, 0.8477])\n",
      "    Recall (A): tensor([0.8563, 0.9663, 0.8437, 0.8026])\n",
      "    F1-Score (A): tensor([0.8708, 0.9447, 0.8269, 0.8245])\n",
      "\n",
      "    Precision (B): tensor([0.0000, 1.0000, 0.7096])\n",
      "    Recall (B): tensor([0.0000, 0.0270, 1.0000])\n",
      "    F1-Score (B): tensor([0.0000, 0.0526, 0.8301])\n",
      "    \n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.494734  [    5/   60]\n",
      "loss: 1.224703  [   10/   60]\n",
      "loss: 1.220127  [   15/   60]\n",
      "loss: 1.597078  [   20/   60]\n",
      "loss: 1.444847  [   25/   60]\n",
      "loss: 1.271567  [   30/   60]\n",
      "loss: 1.487141  [   35/   60]\n",
      "loss: 2.028066  [   40/   60]\n",
      "loss: 1.202067  [   45/   60]\n",
      "loss: 2.111342  [   50/   60]\n",
      "loss: 1.172486  [   55/   60]\n",
      "loss: 1.396800  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.390181\n",
      "    Accuracy: 85.7%\n",
      "\n",
      "    Precision (A): tensor([0.8873, 0.9258, 0.8122, 0.8476])\n",
      "    Recall (A): tensor([0.8579, 0.9658, 0.8421, 0.8079])\n",
      "    F1-Score (A): tensor([0.8724, 0.9454, 0.8269, 0.8273])\n",
      "\n",
      "    Precision (B): tensor([1.0000, 1.0000, 0.7152])\n",
      "    Recall (B): tensor([0.0130, 0.0631, 1.0000])\n",
      "    F1-Score (B): tensor([0.0256, 0.1186, 0.8339])\n",
      "    \n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.438041  [    5/   60]\n",
      "loss: 1.155446  [   10/   60]\n",
      "loss: 1.151202  [   15/   60]\n",
      "loss: 1.542690  [   20/   60]\n",
      "loss: 1.383219  [   25/   60]\n",
      "loss: 1.208378  [   30/   60]\n",
      "loss: 1.428966  [   35/   60]\n",
      "loss: 1.983544  [   40/   60]\n",
      "loss: 1.144904  [   45/   60]\n",
      "loss: 2.071865  [   50/   60]\n",
      "loss: 1.120436  [   55/   60]\n",
      "loss: 1.342637  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.337638\n",
      "    Accuracy: 85.9%\n",
      "\n",
      "    Precision (A): tensor([0.8899, 0.9268, 0.8137, 0.8473])\n",
      "    Recall (A): tensor([0.8589, 0.9658, 0.8416, 0.8121])\n",
      "    F1-Score (A): tensor([0.8741, 0.9459, 0.8274, 0.8293])\n",
      "\n",
      "    Precision (B): tensor([1.0000, 1.0000, 0.7232])\n",
      "    Recall (B): tensor([0.0130, 0.1261, 1.0000])\n",
      "    F1-Score (B): tensor([0.0256, 0.2240, 0.8394])\n",
      "    \n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.392103  [    5/   60]\n",
      "loss: 1.100253  [   10/   60]\n",
      "loss: 1.095879  [   15/   60]\n",
      "loss: 1.497436  [   20/   60]\n",
      "loss: 1.332193  [   25/   60]\n",
      "loss: 1.157646  [   30/   60]\n",
      "loss: 1.380213  [   35/   60]\n",
      "loss: 1.942985  [   40/   60]\n",
      "loss: 1.099821  [   45/   60]\n",
      "loss: 2.035967  [   50/   60]\n",
      "loss: 1.079297  [   55/   60]\n",
      "loss: 1.297808  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.293873\n",
      "    Accuracy: 86.0%\n",
      "\n",
      "    Precision (A): tensor([0.8923, 0.9292, 0.8136, 0.8464])\n",
      "    Recall (A): tensor([0.8589, 0.9674, 0.8411, 0.8147])\n",
      "    F1-Score (A): tensor([0.8753, 0.9479, 0.8271, 0.8302])\n",
      "\n",
      "    Precision (B): tensor([1.0000, 1.0000, 0.7267])\n",
      "    Recall (B): tensor([0.0130, 0.1532, 1.0000])\n",
      "    F1-Score (B): tensor([0.0256, 0.2656, 0.8417])\n",
      "    \n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.354202  [    5/   60]\n",
      "loss: 1.055453  [   10/   60]\n",
      "loss: 1.050546  [   15/   60]\n",
      "loss: 1.459316  [   20/   60]\n",
      "loss: 1.289337  [   25/   60]\n",
      "loss: 1.116242  [   30/   60]\n",
      "loss: 1.338772  [   35/   60]\n",
      "loss: 1.906083  [   40/   60]\n",
      "loss: 1.063788  [   45/   60]\n",
      "loss: 2.003537  [   50/   60]\n",
      "loss: 1.046179  [   55/   60]\n",
      "loss: 1.260247  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.256874\n",
      "    Accuracy: 86.1%\n",
      "\n",
      "    Precision (A): tensor([0.8938, 0.9301, 0.8143, 0.8472])\n",
      "    Recall (A): tensor([0.8595, 0.9668, 0.8426, 0.8168])\n",
      "    F1-Score (A): tensor([0.8763, 0.9481, 0.8282, 0.8317])\n",
      "\n",
      "    Precision (B): tensor([0.5000, 0.9565, 0.7333])\n",
      "    Recall (B): tensor([0.0130, 0.1982, 0.9978])\n",
      "    F1-Score (B): tensor([0.0253, 0.3284, 0.8454])\n",
      "    \n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.322424  [    5/   60]\n",
      "loss: 1.018470  [   10/   60]\n",
      "loss: 1.012661  [   15/   60]\n",
      "loss: 1.426870  [   20/   60]\n",
      "loss: 1.252891  [   25/   60]\n",
      "loss: 1.081927  [   30/   60]\n",
      "loss: 1.303106  [   35/   60]\n",
      "loss: 1.872528  [   40/   60]\n",
      "loss: 1.034628  [   45/   60]\n",
      "loss: 1.974372  [   50/   60]\n",
      "loss: 1.019035  [   55/   60]\n",
      "loss: 1.228425  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.225183\n",
      "    Accuracy: 86.3%\n",
      "\n",
      "    Precision (A): tensor([0.8944, 0.9325, 0.8148, 0.8487])\n",
      "    Recall (A): tensor([0.8600, 0.9668, 0.8426, 0.8211])\n",
      "    F1-Score (A): tensor([0.8768, 0.9494, 0.8285, 0.8347])\n",
      "\n",
      "    Precision (B): tensor([0.6667, 0.9259, 0.7377])\n",
      "    Recall (B): tensor([0.0260, 0.2252, 0.9956])\n",
      "    F1-Score (B): tensor([0.0500, 0.3623, 0.8475])\n",
      "    \n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.295396  [    5/   60]\n",
      "loss: 0.987467  [   10/   60]\n",
      "loss: 0.980415  [   15/   60]\n",
      "loss: 1.399006  [   20/   60]\n",
      "loss: 1.221559  [   25/   60]\n",
      "loss: 1.053082  [   30/   60]\n",
      "loss: 1.272076  [   35/   60]\n",
      "loss: 1.842013  [   40/   60]\n",
      "loss: 1.010758  [   45/   60]\n",
      "loss: 1.948213  [   50/   60]\n",
      "loss: 0.996401  [   55/   60]\n",
      "loss: 1.201189  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.197725\n",
      "    Accuracy: 86.5%\n",
      "\n",
      "    Precision (A): tensor([0.8955, 0.9345, 0.8172, 0.8494])\n",
      "    Recall (A): tensor([0.8616, 0.9679, 0.8421, 0.8253])\n",
      "    F1-Score (A): tensor([0.8782, 0.9509, 0.8294, 0.8372])\n",
      "\n",
      "    Precision (B): tensor([0.7500, 0.8710, 0.7438])\n",
      "    Recall (B): tensor([0.0390, 0.2432, 0.9956])\n",
      "    F1-Score (B): tensor([0.0741, 0.3803, 0.8515])\n",
      "    \n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.272118  [    5/   60]\n",
      "loss: 0.961120  [   10/   60]\n",
      "loss: 0.952508  [   15/   60]\n",
      "loss: 1.374883  [   20/   60]\n",
      "loss: 1.194363  [   25/   60]\n",
      "loss: 1.028524  [   30/   60]\n",
      "loss: 1.244824  [   35/   60]\n",
      "loss: 1.814241  [   40/   60]\n",
      "loss: 0.991010  [   45/   60]\n",
      "loss: 1.924773  [   50/   60]\n",
      "loss: 0.977217  [   55/   60]\n",
      "loss: 1.177660  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.173695\n",
      "    Accuracy: 86.5%\n",
      "\n",
      "    Precision (A): tensor([0.8951, 0.9354, 0.8192, 0.8482])\n",
      "    Recall (A): tensor([0.8621, 0.9684, 0.8416, 0.8263])\n",
      "    F1-Score (A): tensor([0.8783, 0.9516, 0.8302, 0.8371])\n",
      "\n",
      "    Precision (B): tensor([0.8000, 0.8824, 0.7488])\n",
      "    Recall (B): tensor([0.0519, 0.2703, 0.9956])\n",
      "    F1-Score (B): tensor([0.0976, 0.4138, 0.8547])\n",
      "    \n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.251848  [    5/   60]\n",
      "loss: 0.938456  [   10/   60]\n",
      "loss: 0.927992  [   15/   60]\n",
      "loss: 1.353845  [   20/   60]\n",
      "loss: 1.170557  [   25/   60]\n",
      "loss: 1.007373  [   30/   60]\n",
      "loss: 1.220692  [   35/   60]\n",
      "loss: 1.788929  [   40/   60]\n",
      "loss: 0.974516  [   45/   60]\n",
      "loss: 1.903760  [   50/   60]\n",
      "loss: 0.960708  [   55/   60]\n",
      "loss: 1.157156  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.152475\n",
      "    Accuracy: 86.6%\n",
      "\n",
      "    Precision (A): tensor([0.8947, 0.9364, 0.8204, 0.8496])\n",
      "    Recall (A): tensor([0.8626, 0.9684, 0.8437, 0.8268])\n",
      "    F1-Score (A): tensor([0.8783, 0.9521, 0.8319, 0.8381])\n",
      "\n",
      "    Precision (B): tensor([0.8000, 0.8108, 0.7525])\n",
      "    Recall (B): tensor([0.0519, 0.2703, 0.9956])\n",
      "    F1-Score (B): tensor([0.0976, 0.4054, 0.8571])\n",
      "    \n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.234024  [    5/   60]\n",
      "loss: 0.918750  [   10/   60]\n",
      "loss: 0.906171  [   15/   60]\n",
      "loss: 1.335373  [   20/   60]\n",
      "loss: 1.149558  [   25/   60]\n",
      "loss: 0.988970  [   30/   60]\n",
      "loss: 1.199166  [   35/   60]\n",
      "loss: 1.765817  [   40/   60]\n",
      "loss: 0.960617  [   45/   60]\n",
      "loss: 1.884893  [   50/   60]\n",
      "loss: 0.946298  [   55/   60]\n",
      "loss: 1.139143  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.133590\n",
      "    Accuracy: 86.7%\n",
      "\n",
      "    Precision (A): tensor([0.8957, 0.9373, 0.8194, 0.8499])\n",
      "    Recall (A): tensor([0.8637, 0.9679, 0.8453, 0.8258])\n",
      "    F1-Score (A): tensor([0.8794, 0.9524, 0.8321, 0.8377])\n",
      "\n",
      "    Precision (B): tensor([0.8000, 0.7805, 0.7559])\n",
      "    Recall (B): tensor([0.0519, 0.2883, 0.9934])\n",
      "    F1-Score (B): tensor([0.0976, 0.4211, 0.8585])\n",
      "    \n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.218219  [    5/   60]\n",
      "loss: 0.901453  [   10/   60]\n",
      "loss: 0.886524  [   15/   60]\n",
      "loss: 1.319047  [   20/   60]\n",
      "loss: 1.130907  [   25/   60]\n",
      "loss: 0.972810  [   30/   60]\n",
      "loss: 1.179841  [   35/   60]\n",
      "loss: 1.744667  [   40/   60]\n",
      "loss: 0.948810  [   45/   60]\n",
      "loss: 1.867908  [   50/   60]\n",
      "loss: 0.933559  [   55/   60]\n",
      "loss: 1.123201  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.116666\n",
      "    Accuracy: 86.7%\n",
      "\n",
      "    Precision (A): tensor([0.8953, 0.9383, 0.8196, 0.8513])\n",
      "    Recall (A): tensor([0.8642, 0.9684, 0.8463, 0.8258])\n",
      "    F1-Score (A): tensor([0.8795, 0.9531, 0.8327, 0.8384])\n",
      "\n",
      "    Precision (B): tensor([0.8000, 0.7500, 0.7580])\n",
      "    Recall (B): tensor([0.0519, 0.2973, 0.9912])\n",
      "    F1-Score (B): tensor([0.0976, 0.4258, 0.8591])\n",
      "    \n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.204099  [    5/   60]\n",
      "loss: 0.886146  [   10/   60]\n",
      "loss: 0.868660  [   15/   60]\n",
      "loss: 1.304527  [   20/   60]\n",
      "loss: 1.114237  [   25/   60]\n",
      "loss: 0.958503  [   30/   60]\n",
      "loss: 1.162393  [   35/   60]\n",
      "loss: 1.725268  [   40/   60]\n",
      "loss: 0.938706  [   45/   60]\n",
      "loss: 1.852567  [   50/   60]\n",
      "loss: 0.922167  [   55/   60]\n",
      "loss: 1.108992  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.101403\n",
      "    Accuracy: 86.7%\n",
      "\n",
      "    Precision (A): tensor([0.8954, 0.9393, 0.8197, 0.8508])\n",
      "    Recall (A): tensor([0.8647, 0.9684, 0.8468, 0.8253])\n",
      "    F1-Score (A): tensor([0.8798, 0.9536, 0.8330, 0.8378])\n",
      "\n",
      "    Precision (B): tensor([0.8000, 0.7556, 0.7593])\n",
      "    Recall (B): tensor([0.0519, 0.3063, 0.9912])\n",
      "    F1-Score (B): tensor([0.0976, 0.4359, 0.8599])\n",
      "    \n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.191401  [    5/   60]\n",
      "loss: 0.872501  [   10/   60]\n",
      "loss: 0.852280  [   15/   60]\n",
      "loss: 1.291536  [   20/   60]\n",
      "loss: 1.099250  [   25/   60]\n",
      "loss: 0.945744  [   30/   60]\n",
      "loss: 1.146558  [   35/   60]\n",
      "loss: 1.707427  [   40/   60]\n",
      "loss: 0.930000  [   45/   60]\n",
      "loss: 1.838659  [   50/   60]\n",
      "loss: 0.911873  [   55/   60]\n",
      "loss: 1.096245  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.087562\n",
      "    Accuracy: 86.8%\n",
      "\n",
      "    Precision (A): tensor([0.8955, 0.9412, 0.8194, 0.8512])\n",
      "    Recall (A): tensor([0.8658, 0.9684, 0.8479, 0.8253])\n",
      "    F1-Score (A): tensor([0.8804, 0.9546, 0.8334, 0.8381])\n",
      "\n",
      "    Precision (B): tensor([0.8000, 0.7660, 0.7619])\n",
      "    Recall (B): tensor([0.0519, 0.3243, 0.9912])\n",
      "    F1-Score (B): tensor([0.0976, 0.4557, 0.8615])\n",
      "    \n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.179913  [    5/   60]\n",
      "loss: 0.860259  [   10/   60]\n",
      "loss: 0.837151  [   15/   60]\n",
      "loss: 1.279845  [   20/   60]\n",
      "loss: 1.085704  [   25/   60]\n",
      "loss: 0.934291  [   30/   60]\n",
      "loss: 1.132120  [   35/   60]\n",
      "loss: 1.690977  [   40/   60]\n",
      "loss: 0.922449  [   45/   60]\n",
      "loss: 1.825997  [   50/   60]\n",
      "loss: 0.902486  [   55/   60]\n",
      "loss: 1.084742  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.074948\n",
      "    Accuracy: 86.8%\n",
      "\n",
      "    Precision (A): tensor([0.8956, 0.9412, 0.8198, 0.8528])\n",
      "    Recall (A): tensor([0.8668, 0.9689, 0.8474, 0.8263])\n",
      "    F1-Score (A): tensor([0.8810, 0.9549, 0.8333, 0.8393])\n",
      "\n",
      "    Precision (B): tensor([0.8333, 0.7255, 0.7650])\n",
      "    Recall (B): tensor([0.0649, 0.3333, 0.9867])\n",
      "    F1-Score (B): tensor([0.1205, 0.4568, 0.8618])\n",
      "    \n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.169464  [    5/   60]\n",
      "loss: 0.849213  [   10/   60]\n",
      "loss: 0.823093  [   15/   60]\n",
      "loss: 1.269266  [   20/   60]\n",
      "loss: 1.073400  [   25/   60]\n",
      "loss: 0.923950  [   30/   60]\n",
      "loss: 1.118901  [   35/   60]\n",
      "loss: 1.675770  [   40/   60]\n",
      "loss: 0.915861  [   45/   60]\n",
      "loss: 1.814417  [   50/   60]\n",
      "loss: 0.893856  [   55/   60]\n",
      "loss: 1.074303  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.063398\n",
      "    Accuracy: 86.9%\n",
      "\n",
      "    Precision (A): tensor([0.8975, 0.9412, 0.8205, 0.8522])\n",
      "    Recall (A): tensor([0.8668, 0.9695, 0.8468, 0.8284])\n",
      "    F1-Score (A): tensor([0.8819, 0.9551, 0.8335, 0.8401])\n",
      "\n",
      "    Precision (B): tensor([0.8333, 0.7308, 0.7663])\n",
      "    Recall (B): tensor([0.0649, 0.3423, 0.9867])\n",
      "    F1-Score (B): tensor([0.1205, 0.4663, 0.8627])\n",
      "    \n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.159915  [    5/   60]\n",
      "loss: 0.839196  [   10/   60]\n",
      "loss: 0.809962  [   15/   60]\n",
      "loss: 1.259641  [   20/   60]\n",
      "loss: 1.062172  [   25/   60]\n",
      "loss: 0.914562  [   30/   60]\n",
      "loss: 1.106752  [   35/   60]\n",
      "loss: 1.661674  [   40/   60]\n",
      "loss: 0.910080  [   45/   60]\n",
      "loss: 1.803781  [   50/   60]\n",
      "loss: 0.885867  [   55/   60]\n",
      "loss: 1.064780  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.052780\n",
      "    Accuracy: 87.0%\n",
      "\n",
      "    Precision (A): tensor([0.8986, 0.9417, 0.8222, 0.8516])\n",
      "    Recall (A): tensor([0.8674, 0.9695, 0.8468, 0.8305])\n",
      "    F1-Score (A): tensor([0.8827, 0.9554, 0.8343, 0.8409])\n",
      "\n",
      "    Precision (B): tensor([0.8333, 0.7222, 0.7672])\n",
      "    Recall (B): tensor([0.0649, 0.3514, 0.9845])\n",
      "    F1-Score (B): tensor([0.1205, 0.4727, 0.8624])\n",
      "    \n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.151149  [    5/   60]\n",
      "loss: 0.830069  [   10/   60]\n",
      "loss: 0.797643  [   15/   60]\n",
      "loss: 1.250839  [   20/   60]\n",
      "loss: 1.051881  [   25/   60]\n",
      "loss: 0.905997  [   30/   60]\n",
      "loss: 1.095546  [   35/   60]\n",
      "loss: 1.648576  [   40/   60]\n",
      "loss: 0.904979  [   45/   60]\n",
      "loss: 1.793967  [   50/   60]\n",
      "loss: 0.878423  [   55/   60]\n",
      "loss: 1.056050  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.042982\n",
      "    Accuracy: 87.1%\n",
      "\n",
      "    Precision (A): tensor([0.8982, 0.9422, 0.8239, 0.8528])\n",
      "    Recall (A): tensor([0.8684, 0.9700, 0.8468, 0.8321])\n",
      "    F1-Score (A): tensor([0.8831, 0.9559, 0.8352, 0.8423])\n",
      "\n",
      "    Precision (B): tensor([0.8571, 0.7222, 0.7686])\n",
      "    Recall (B): tensor([0.0779, 0.3514, 0.9845])\n",
      "    F1-Score (B): tensor([0.1429, 0.4727, 0.8632])\n",
      "    \n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.143069  [    5/   60]\n",
      "loss: 0.821721  [   10/   60]\n",
      "loss: 0.786041  [   15/   60]\n",
      "loss: 1.242751  [   20/   60]\n",
      "loss: 1.042411  [   25/   60]\n",
      "loss: 0.898148  [   30/   60]\n",
      "loss: 1.085178  [   35/   60]\n",
      "loss: 1.636374  [   40/   60]\n",
      "loss: 0.900453  [   45/   60]\n",
      "loss: 1.784870  [   50/   60]\n",
      "loss: 0.871449  [   55/   60]\n",
      "loss: 1.048013  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.033908\n",
      "    Accuracy: 87.1%\n",
      "\n",
      "    Precision (A): tensor([0.8987, 0.9422, 0.8232, 0.8536])\n",
      "    Recall (A): tensor([0.8684, 0.9700, 0.8479, 0.8316])\n",
      "    F1-Score (A): tensor([0.8833, 0.9559, 0.8354, 0.8424])\n",
      "\n",
      "    Precision (B): tensor([0.8889, 0.7091, 0.7708])\n",
      "    Recall (B): tensor([0.1039, 0.3514, 0.9823])\n",
      "    F1-Score (B): tensor([0.1860, 0.4699, 0.8638])\n",
      "    \n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.135594  [    5/   60]\n",
      "loss: 0.814055  [   10/   60]\n",
      "loss: 0.775079  [   15/   60]\n",
      "loss: 1.235283  [   20/   60]\n",
      "loss: 1.033663  [   25/   60]\n",
      "loss: 0.890926  [   30/   60]\n",
      "loss: 1.075555  [   35/   60]\n",
      "loss: 1.624982  [   40/   60]\n",
      "loss: 0.896415  [   45/   60]\n",
      "loss: 1.776404  [   50/   60]\n",
      "loss: 0.864884  [   55/   60]\n",
      "loss: 1.040582  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.025480\n",
      "    Accuracy: 87.1%\n",
      "\n",
      "    Precision (A): tensor([0.8992, 0.9427, 0.8241, 0.8528])\n",
      "    Recall (A): tensor([0.8684, 0.9700, 0.8484, 0.8321])\n",
      "    F1-Score (A): tensor([0.8835, 0.9562, 0.8361, 0.8423])\n",
      "\n",
      "    Precision (B): tensor([0.9000, 0.7018, 0.7731])\n",
      "    Recall (B): tensor([0.1169, 0.3604, 0.9801])\n",
      "    F1-Score (B): tensor([0.2069, 0.4762, 0.8644])\n",
      "    \n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.128652  [    5/   60]\n",
      "loss: 0.806992  [   10/   60]\n",
      "loss: 0.764694  [   15/   60]\n",
      "loss: 1.228358  [   20/   60]\n",
      "loss: 1.025555  [   25/   60]\n",
      "loss: 0.884254  [   30/   60]\n",
      "loss: 1.066600  [   35/   60]\n",
      "loss: 1.614320  [   40/   60]\n",
      "loss: 0.892795  [   45/   60]\n",
      "loss: 1.768491  [   50/   60]\n",
      "loss: 0.858678  [   55/   60]\n",
      "loss: 1.033684  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.017627\n",
      "    Accuracy: 87.2%\n",
      "\n",
      "    Precision (A): tensor([0.8996, 0.9437, 0.8255, 0.8531])\n",
      "    Recall (A): tensor([0.8679, 0.9705, 0.8489, 0.8347])\n",
      "    F1-Score (A): tensor([0.8835, 0.9569, 0.8371, 0.8438])\n",
      "\n",
      "    Precision (B): tensor([0.9000, 0.7069, 0.7745])\n",
      "    Recall (B): tensor([0.1169, 0.3694, 0.9801])\n",
      "    F1-Score (B): tensor([0.2069, 0.4852, 0.8652])\n",
      "    \n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.122186  [    5/   60]\n",
      "loss: 0.800463  [   10/   60]\n",
      "loss: 0.754831  [   15/   60]\n",
      "loss: 1.221910  [   20/   60]\n",
      "loss: 1.018013  [   25/   60]\n",
      "loss: 0.878068  [   30/   60]\n",
      "loss: 1.058244  [   35/   60]\n",
      "loss: 1.604320  [   40/   60]\n",
      "loss: 0.889531  [   45/   60]\n",
      "loss: 1.761066  [   50/   60]\n",
      "loss: 0.852788  [   55/   60]\n",
      "loss: 1.027259  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.010291\n",
      "    Accuracy: 87.2%\n",
      "\n",
      "    Precision (A): tensor([0.8997, 0.9447, 0.8252, 0.8535])\n",
      "    Recall (A): tensor([0.8689, 0.9705, 0.8495, 0.8342])\n",
      "    F1-Score (A): tensor([0.8841, 0.9574, 0.8371, 0.8438])\n",
      "\n",
      "    Precision (B): tensor([0.8182, 0.7000, 0.7750])\n",
      "    Recall (B): tensor([0.1169, 0.3784, 0.9757])\n",
      "    F1-Score (B): tensor([0.2045, 0.4912, 0.8639])\n",
      "    \n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.116143  [    5/   60]\n",
      "loss: 0.794410  [   10/   60]\n",
      "loss: 0.745444  [   15/   60]\n",
      "loss: 1.215881  [   20/   60]\n",
      "loss: 1.010978  [   25/   60]\n",
      "loss: 0.872313  [   30/   60]\n",
      "loss: 1.050430  [   35/   60]\n",
      "loss: 1.594923  [   40/   60]\n",
      "loss: 0.886573  [   45/   60]\n",
      "loss: 1.754075  [   50/   60]\n",
      "loss: 0.847180  [   55/   60]\n",
      "loss: 1.021254  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 1.003421\n",
      "    Accuracy: 87.2%\n",
      "\n",
      "    Precision (A): tensor([0.9008, 0.9447, 0.8255, 0.8531])\n",
      "    Recall (A): tensor([0.8700, 0.9711, 0.8489, 0.8342])\n",
      "    F1-Score (A): tensor([0.8851, 0.9577, 0.8371, 0.8435])\n",
      "\n",
      "    Precision (B): tensor([0.7692, 0.7119, 0.7746])\n",
      "    Recall (B): tensor([0.1299, 0.3784, 0.9735])\n",
      "    F1-Score (B): tensor([0.2222, 0.4941, 0.8627])\n",
      "    \n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.110480  [    5/   60]\n",
      "loss: 0.788784  [   10/   60]\n",
      "loss: 0.736495  [   15/   60]\n",
      "loss: 1.210224  [   20/   60]\n",
      "loss: 1.004395  [   25/   60]\n",
      "loss: 0.866943  [   30/   60]\n",
      "loss: 1.043104  [   35/   60]\n",
      "loss: 1.586075  [   40/   60]\n",
      "loss: 0.883878  [   45/   60]\n",
      "loss: 1.747469  [   50/   60]\n",
      "loss: 0.841825  [   55/   60]\n",
      "loss: 1.015624  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 0.996972\n",
      "    Accuracy: 87.3%\n",
      "\n",
      "    Precision (A): tensor([0.9023, 0.9448, 0.8279, 0.8525])\n",
      "    Recall (A): tensor([0.8700, 0.9732, 0.8484, 0.8363])\n",
      "    F1-Score (A): tensor([0.8859, 0.9588, 0.8381, 0.8443])\n",
      "\n",
      "    Precision (B): tensor([0.7857, 0.7119, 0.7760])\n",
      "    Recall (B): tensor([0.1429, 0.3784, 0.9735])\n",
      "    F1-Score (B): tensor([0.2418, 0.4941, 0.8636])\n",
      "    \n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.105157  [    5/   60]\n",
      "loss: 0.783540  [   10/   60]\n",
      "loss: 0.727949  [   15/   60]\n",
      "loss: 1.204898  [   20/   60]\n",
      "loss: 0.998220  [   25/   60]\n",
      "loss: 0.861916  [   30/   60]\n",
      "loss: 1.036222  [   35/   60]\n",
      "loss: 1.577729  [   40/   60]\n",
      "loss: 0.881410  [   45/   60]\n",
      "loss: 1.741207  [   50/   60]\n",
      "loss: 0.836698  [   55/   60]\n",
      "loss: 1.010331  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 0.990905\n",
      "    Accuracy: 87.4%\n",
      "\n",
      "    Precision (A): tensor([0.9023, 0.9448, 0.8284, 0.8520])\n",
      "    Recall (A): tensor([0.8700, 0.9732, 0.8484, 0.8363])\n",
      "    F1-Score (A): tensor([0.8859, 0.9588, 0.8383, 0.8441])\n",
      "\n",
      "    Precision (B): tensor([0.8125, 0.7119, 0.7788])\n",
      "    Recall (B): tensor([0.1688, 0.3784, 0.9735])\n",
      "    F1-Score (B): tensor([0.2796, 0.4941, 0.8653])\n",
      "    \n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.100141  [    5/   60]\n",
      "loss: 0.778641  [   10/   60]\n",
      "loss: 0.719776  [   15/   60]\n",
      "loss: 1.199867  [   20/   60]\n",
      "loss: 0.992412  [   25/   60]\n",
      "loss: 0.857197  [   30/   60]\n",
      "loss: 1.029744  [   35/   60]\n",
      "loss: 1.569842  [   40/   60]\n",
      "loss: 0.879137  [   45/   60]\n",
      "loss: 1.735253  [   50/   60]\n",
      "loss: 0.831778  [   55/   60]\n",
      "loss: 1.005340  [   60/   60]\n",
      "Test Error:\n",
      "    Avg loss: 0.985186\n",
      "    Accuracy: 87.4%\n",
      "\n",
      "    Precision (A): tensor([0.9038, 0.9448, 0.8288, 0.8522])\n",
      "    Recall (A): tensor([0.8700, 0.9737, 0.8484, 0.8379])\n",
      "    F1-Score (A): tensor([0.8866, 0.9590, 0.8385, 0.8450])\n",
      "\n",
      "    Precision (B): tensor([0.8125, 0.7049, 0.7815])\n",
      "    Recall (B): tensor([0.1688, 0.3874, 0.9735])\n",
      "    F1-Score (B): tensor([0.2796, 0.5000, 0.8670])\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformerWithHeads(num_classes_a=4, num_classes_b=3).to(device)\n",
    "model.train()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader_a, train_dataloader_b, model, loss_fn, optimizer)\n",
    "    test(test_dataloader_a, test_dataloader_b, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec991a3-1abc-4ece-b354-ad089c2be292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
